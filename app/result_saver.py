#!/usr/bin/env python3
"""
Modu do zapisywania wynik贸w transkrypcji i analizy
===================================================

Zawiera funkcje do:
- Zapisywania transkrypcji z informacjami o m贸wcach
- Zapisywania analizy treci przez Ollama
- Zapisywania rozumowania modeli (opcjonalnie)
- Formatowania wynik贸w w czytelny spos贸b
- Obsugi r贸偶nych format贸w wyjciowych
"""

import copy
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, List, Union

from .reasoning_filter import ReasoningFilter

logger = logging.getLogger(__name__)

class ResultSaver:
    """Zapisywanie wynik贸w transkrypcji i analizy do plik贸w"""
    
    def __init__(
        self,
        output_folder: Union[str, Path] = "output",
    ):
        self.output_folder = Path(output_folder)
        self.output_folder.mkdir(parents=True, exist_ok=True)
        self.reasoning_filter = ReasoningFilter()
        logger.info(f"ResultSaver zainicjalizowany - folder: {self.output_folder}")
    
    def find_speaker_for_segment(self, segment_start: float, segment_end: float, 
                                speakers_data: List[Dict]) -> str:
        """Znajdowanie m贸wcy dla segmentu z ulepszonym algorytmem dopasowania"""
        if not speakers_data:
            return "Unknown"
        
        best_speaker = "Unknown"
        best_overlap = 0.0
        
        for speaker_info in speakers_data:
            speaker_start = speaker_info["start"]
            speaker_end = speaker_info["end"]
            
            # Obliczenie nakadania si segment贸w
            overlap_start = max(segment_start, speaker_start)
            overlap_end = min(segment_end, speaker_end)
            
            if overlap_end > overlap_start:  # Jest nakadanie
                overlap_duration = overlap_end - overlap_start
                segment_duration = segment_end - segment_start
                
                # Procent nakadania wzgldem segmentu
                overlap_ratio = overlap_duration / segment_duration
                
                if overlap_ratio > best_overlap:
                    best_overlap = overlap_ratio
                    best_speaker = speaker_info["speaker"]
        
        # Jeli nakadanie jest mniejsze ni偶 50%, sprawd藕 najbli偶szy segment
        if best_overlap < 0.5:
            best_speaker = self._find_closest_speaker(segment_start, segment_end, speakers_data)
        
        return best_speaker
    
    def _find_closest_speaker(self, segment_start: float, segment_end: float, 
                             speakers_data: List[Dict]) -> str:
        """Znajdowanie najbli偶szego segmentu m贸wcy"""
        if not speakers_data:
            return "Unknown"
        
        segment_center = (segment_start + segment_end) / 2
        closest_speaker = "Unknown"
        min_distance = float('inf')
        
        for speaker_info in speakers_data:
            speaker_center = (speaker_info["start"] + speaker_info["end"]) / 2
            distance = abs(segment_center - speaker_center)
            
            if distance < min_distance:
                min_distance = distance
                closest_speaker = speaker_info["speaker"]
        
        return closest_speaker
    
    def merge_consecutive_speakers(self, segments_with_speakers: List[Dict]) -> List[Dict]:
        """czenie kolejnych segment贸w tego samego m贸wcy"""
        if not segments_with_speakers:
            return segments_with_speakers
        
        merged = []
        current_group = {
            "speaker": segments_with_speakers[0]["speaker"],
            "start": segments_with_speakers[0]["start"],
            "end": segments_with_speakers[0]["end"],
            "text": segments_with_speakers[0]["text"]
        }
        
        for i in range(1, len(segments_with_speakers)):
            current_seg = segments_with_speakers[i]
            
            # Sprawdzenie czy mo偶na poczy (ten sam m贸wca, maa pauza)
            if (current_seg["speaker"] == current_group["speaker"] and 
                current_seg["start"] - current_group["end"] < 1.0):  # Pauza < 1s
                
                # Rozszerzenie grupy
                current_group["end"] = current_seg["end"]
                current_group["text"] += " " + current_seg["text"]
            else:
                # Zapisanie grupy i rozpoczcie nowej
                merged.append(current_group)
                current_group = {
                    "speaker": current_seg["speaker"],
                    "start": current_seg["start"],
                    "end": current_seg["end"],
                    "text": current_seg["text"]
                }
        
        # Dodanie ostatniej grupy
        merged.append(current_group)
        
        return merged
    
    def save_transcription_with_speakers(
        self,
        audio_file_path: Path,
        transcription_data: Dict,
        analysis_results: Optional[Dict] = None,
        timestamp: Optional[str] = None,
    ) -> str:
        """Zapisywanie transkrypcji z informacjami o m贸wcach i analiz Ollama."""
        try:
            effective_timestamp = timestamp or datetime.now().strftime("%Y%m%d%H%M%S")
            output_filename = f"{audio_file_path.stem} {effective_timestamp}.txt"
            output_path = self.output_folder / output_filename

            analysis_filename = f"{audio_file_path.stem} ANALIZA {effective_timestamp}.txt"
            analysis_path = self.output_folder / analysis_filename

            # Zapisanie transkrypcji tekstowej z rozpoznawaniem m贸wc贸w
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"Transkrypcja rozmowy: {audio_file_path.name}\n")
                f.write("=" * 60 + "\n\n")
                
                segments = transcription_data.get("segments", [])
                speakers_data = transcription_data.get("speakers", [])
                
                # Przygotowanie segment贸w z przypisanymi m贸wcami
                segments_with_speakers = []
                for segment in segments:
                    segment_start = segment.get("start", 0)
                    segment_end = segment.get("end", 0)
                    
                    # Znajd藕 m贸wc dla tego segmentu
                    speaker = self.find_speaker_for_segment(segment_start, segment_end, speakers_data)
                    
                    segments_with_speakers.append({
                        "speaker": speaker,
                        "start": segment_start,
                        "end": segment_end,
                        "text": segment.get("text", "").strip()
                    })
                
                # czenie kolejnych segment贸w tego samego m贸wcy
                merged_segments = self.merge_consecutive_speakers(segments_with_speakers)
                
                # Zapisanie do pliku
                for segment in merged_segments:
                    start_time = f"{int(segment['start']//60):02d}:{int(segment['start']%60):02d}"
                    end_time = f"{int(segment['end']//60):02d}:{int(segment['end']%60):02d}"
                    f.write(f"[{start_time}-{end_time}] {segment['speaker']}: {segment['text']}\n")
                
                # Dodanie statystyk m贸wc贸w
                f.write("\n" + "=" * 60 + "\n")
                f.write("STATYSTYKI MWCW:\n")
                f.write("=" * 60 + "\n")
                
                speaker_stats = {}
                for segment in merged_segments:
                    speaker = segment["speaker"]
                    duration = segment["end"] - segment["start"]
                    
                    if speaker not in speaker_stats:
                        speaker_stats[speaker] = {"total_time": 0, "segments": 0, "words": 0}
                    
                    speaker_stats[speaker]["total_time"] += duration
                    speaker_stats[speaker]["segments"] += 1
                    speaker_stats[speaker]["words"] += len(segment["text"].split())
                
                for speaker, stats in speaker_stats.items():
                    total_minutes = stats["total_time"] / 60
                    avg_words_per_segment = stats["words"] / stats["segments"] if stats["segments"] > 0 else 0
                    f.write(f"{speaker}:\n")
                    f.write(f"  - Czas m贸wienia: {stats['total_time']:.1f}s ({total_minutes:.1f}min)\n")
                    f.write(f"  - Liczba segment贸w: {stats['segments']}\n")
                    f.write(f"  - Liczba s贸w: {stats['words']}\n")
                    f.write(f"  - rednio s贸w/segment: {avg_words_per_segment:.1f}\n")
                    f.write("\n")
            
            analysis_text = self._prepare_analysis_text(analysis_results, audio_file_path)
            with open(analysis_path, "w", encoding="utf-8") as f:
                f.write(f"Analiza rozmowy: {audio_file_path.name}\n")
                f.write("=" * 60 + "\n\n")
                f.write(analysis_text)

            # Zapisywanie rozumowania do osobnego pliku (jeli wczone)
            if (
                analysis_results
                and analysis_results.get("content_analysis", {}).get("filtered_reasoning")
            ):
                self.reasoning_filter.save_reasoning_to_file(
                    analysis_results["content_analysis"]["filtered_reasoning"],
                    self.output_folder,
                    audio_file_path.stem,
                )

            logger.success("Analiza zapisana: %s", analysis_path)

            logger.success(f"Transkrypcja zapisana: {output_path}")
            return effective_timestamp
            
        except Exception as e:
            logger.error(f"Bd podczas zapisywania transkrypcji: {e}")
            raise
    
    def _prepare_analysis_text(
        self, analysis_results: Optional[Dict], audio_file_path: Path
    ) -> str:
        """Tworzy tekst analizy nawet jeli Ollama jest niedostpna."""
        if not analysis_results:
            return (
                "Analiza Ollama niedostpna. "
                "Sprawd藕 konfiguracj serwera lub ustaw zmienn ENABLE_OLLAMA_ANALYSIS=false."
            )

        content_analysis = analysis_results.get("content_analysis")
        if content_analysis:
            if content_analysis.get("injection_detected"):
                warning = (
                    "锔 Wykryto potencjaln pr贸b manipulacji transkrypcj. "
                    f"Sowa-klucze: {', '.join(content_analysis.get('injection_matches', []))}\n\n"
                )
            else:
                warning = ""

            if not content_analysis.get("success"):
                error_detail = (
                    content_analysis.get("validation_error")
                    or content_analysis.get("error")
                    or "Nieznany bd analizy"
                )
                return warning + f"Analiza Ollama zakoczona bdem: {error_detail}"

            if content_analysis.get("raw_response"):
                return warning + content_analysis["raw_response"]

        if content_analysis and content_analysis.get("parsed_result"):
            try:
                parsed = content_analysis["parsed_result"]
                # Jeli jest brief_summary, wywietl je na pocztku
                if isinstance(parsed, dict) and "brief_summary" in parsed:
                    parsed_copy = copy.deepcopy(parsed)
                    brief = parsed_copy.pop("brief_summary")
                    result = f" Kr贸tkie podsumowanie rozmowy:\n{brief}\n\n"
                    result += " Szczeg贸owa analiza:\n"
                    result += json.dumps(parsed_copy, ensure_ascii=False, indent=2)
                    return warning + result
                else:
                    return warning + json.dumps(parsed, ensure_ascii=False, indent=2)
            except Exception:
                return warning + str(content_analysis["parsed_result"])

        return (
            f"Analiza Ollama niedostpna dla pliku {audio_file_path.name}. "
            f"Szczeg贸y: {analysis_results}"
        )
