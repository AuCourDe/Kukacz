#!/usr/bin/env python3
"""
ModuÅ‚ do integracji z Ollama dla analizy treÅ›ci
"""

import requests
import json
import logging
from typing import Dict, List, Optional, Any
from pathlib import Path

logger = logging.getLogger(__name__)

class OllamaAnalyzer:
    """Klasa do analizy treÅ›ci za pomocÄ… Ollama"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "qwen3:8b"):
        self.base_url = base_url
        self.model = model
        self.api_url = f"{base_url}/api/generate"
        
        logger.info(f"OllamaAnalyzer zainicjalizowany z modelem: {model}")
        logger.info(f"API URL: {self.api_url}")
    
    def test_connection(self) -> bool:
        """Test poÅ‚Ä…czenia z serwerem Ollama"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [model["name"] for model in models]
                logger.info(f"DostÄ™pne modele Ollama: {available_models}")
                
                if self.model in available_models:
                    logger.info(f"Model {self.model} jest dostÄ™pny")
                    return True
                else:
                    logger.warning(f"Model {self.model} nie jest dostÄ™pny. DostÄ™pne: {available_models}")
                    return False
            else:
                logger.error(f"BÅ‚Ä…d poÅ‚Ä…czenia z Ollama: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas testowania poÅ‚Ä…czenia z Ollama: {e}")
            return False
    
    def analyze_content(self, text: str, analysis_type: str = "general") -> Dict[str, Any]:
        """
        Analiza treÅ›ci za pomocÄ… Ollama
        
        Args:
            text: Tekst do analizy
            analysis_type: Typ analizy ("general", "sentiment", "content_quality", "call_center", "custom")
        
        Returns:
            SÅ‚ownik z wynikami analizy
        """
        try:
            # Import konfiguracji
            from config import OLLAMA_PROMPTS, OLLAMA_GENERATION_PARAMS
            
            # Przygotowanie promptu w zaleÅ¼noÅ›ci od typu analizy
            if analysis_type in OLLAMA_PROMPTS:
                # UÅ¼yj promptu z konfiguracji
                prompt = OLLAMA_PROMPTS[analysis_type].format(text=text)
            elif analysis_type == "call_center":
                prompt = self._create_call_center_prompt(text)
            elif analysis_type == "sentiment":
                prompt = self._create_sentiment_prompt(text)
            elif analysis_type == "content_quality":
                prompt = self._create_content_quality_prompt(text)
            else:
                prompt = self._create_general_prompt(text)
            
            # WywoÅ‚anie API Ollama
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": OLLAMA_GENERATION_PARAMS
            }
            
            logger.info(f"WysyÅ‚anie zapytania do Ollama (typ: {analysis_type})")
            response = requests.post(self.api_url, json=payload, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                analysis_text = result.get("response", "").strip()
                
                # Parsowanie odpowiedzi
                parsed_result = self._parse_analysis_response(analysis_text, analysis_type)
                
                logger.info(f"Analiza zakoÅ„czona pomyÅ›lnie (typ: {analysis_type})")
                return {
                    "success": True,
                    "analysis_type": analysis_type,
                    "raw_response": analysis_text,
                    "parsed_result": parsed_result,
                    "model_used": self.model
                }
            else:
                logger.error(f"BÅ‚Ä…d API Ollama: {response.status_code} - {response.text}")
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "analysis_type": analysis_type
                }
                
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas analizy treÅ›ci: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_type": analysis_type
            }
    
    def _create_call_center_prompt(self, text: str) -> str:
        """Tworzenie promptu dla analizy rozmÃ³w call center"""
        return f"""Podsumuj rozmowÄ™ w dwÃ³ch krÃ³tkich zdaniach. W trzecim zdaniu oceÅ„, czy byÅ‚a ona pozytywna, negatywna, czy przebiegÅ‚a w miÅ‚ym tonie. JeÅ¼eli ktoÅ› podczas rozmowy byÅ‚ agresywny lub wulgarny lub niemiÅ‚y to podaj kto to byÅ‚ i co dokÅ‚adnie powiedziaÅ‚.

Transkrypcja rozmowy:
{text}

OdpowiedÅº:"""

    def _create_sentiment_prompt(self, text: str) -> str:
        """Tworzenie promptu dla analizy sentymentu"""
        return f"""Przeanalizuj sentyment poniÅ¼szego tekstu i zwrÃ³Ä‡ odpowiedÅº w formacie JSON:

Tekst:
{text}

OdpowiedÅº w formacie JSON:
{{
    "sentiment": "positive/negative/neutral",
    "confidence": 0.85,
    "emotions": ["satisfaction", "frustration"],
    "intensity": "high/medium/low"
}}"""

    def _create_content_quality_prompt(self, text: str) -> str:
        """Tworzenie promptu dla analizy jakoÅ›ci treÅ›ci"""
        return f"""Przeanalizuj jakoÅ›Ä‡ poniÅ¼szego tekstu i zwrÃ³Ä‡ odpowiedÅº w formacie JSON:

Tekst:
{text}

OdpowiedÅº w formacie JSON:
{{
    "readability": 7.5,
    "clarity": 8.0,
    "completeness": 6.5,
    "issues": ["grammar_errors", "unclear_phrases"],
    "suggestions": ["poprawiÄ‡ gramatykÄ™", "dodaÄ‡ szczegÃ³Å‚y"]
}}"""

    def _create_general_prompt(self, text: str) -> str:
        """Tworzenie ogÃ³lnego promptu analizy"""
        return f"""Przeanalizuj poniÅ¼szy tekst i zwrÃ³Ä‡ ogÃ³lne podsumowanie w formacie JSON:

Tekst:
{text}

OdpowiedÅº w formacie JSON:
{{
    "summary": "krÃ³tkie podsumowanie",
    "key_points": ["punkt 1", "punkt 2"],
    "tone": "formal/informal",
    "length_category": "short/medium/long"
}}"""

    def _parse_analysis_response(self, response_text: str, analysis_type: str) -> Dict[str, Any]:
        """Parsowanie odpowiedzi z Ollama"""
        try:
            # PrÃ³ba wyodrÄ™bnienia JSON z odpowiedzi
            if "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                json_str = response_text[start:end]
                return json.loads(json_str)
            else:
                # JeÅ›li nie ma JSON, zwrÃ³Ä‡ surowy tekst
                return {
                    "raw_analysis": response_text,
                    "parsing_error": "Nie znaleziono formatu JSON"
                }
        except json.JSONDecodeError as e:
            logger.warning(f"BÅ‚Ä…d parsowania JSON: {e}")
            return {
                "raw_analysis": response_text,
                "parsing_error": str(e)
            }
    
    def analyze_speaker_patterns(self, speakers_data: List[Dict]) -> Dict[str, Any]:
        """Analiza wzorcÃ³w mÃ³wcÃ³w"""
        if not speakers_data:
            return {"error": "Brak danych o mÃ³wcach"}
        
        try:
            # Statystyki mÃ³wcÃ³w
            speaker_stats = {}
            total_duration = 0
            
            for speaker_info in speakers_data:
                speaker = speaker_info["speaker"]
                duration = speaker_info["duration"]
                
                if speaker not in speaker_stats:
                    speaker_stats[speaker] = {
                        "total_time": 0,
                        "segments": 0,
                        "avg_segment_length": 0
                    }
                
                speaker_stats[speaker]["total_time"] += duration
                speaker_stats[speaker]["segments"] += 1
                total_duration += duration
            
            # Obliczenie Å›rednich
            for speaker in speaker_stats:
                stats = speaker_stats[speaker]
                stats["avg_segment_length"] = stats["total_time"] / stats["segments"]
                stats["percentage"] = (stats["total_time"] / total_duration) * 100
            
            # Analiza wzorcÃ³w
            dominant_speaker = max(speaker_stats.keys(), 
                                 key=lambda x: speaker_stats[x]["total_time"])
            
            return {
                "speaker_stats": speaker_stats,
                "total_duration": total_duration,
                "dominant_speaker": dominant_speaker,
                "speaker_count": len(speaker_stats),
                "analysis": {
                    "conversation_balance": "balanced" if len(speaker_stats) == 2 else "unbalanced",
                    "dominant_speaker_percentage": speaker_stats[dominant_speaker]["percentage"]
                }
            }
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas analizy wzorcÃ³w mÃ³wcÃ³w: {e}")
            return {"error": str(e)}

def test_ollama_integration():
    """Test integracji z Ollama"""
    print("ğŸ§ª Test integracji z Ollama")
    print("=" * 40)
    
    analyzer = OllamaAnalyzer()
    
    # Test poÅ‚Ä…czenia
    print("1. Test poÅ‚Ä…czenia z serwerem Ollama...")
    if analyzer.test_connection():
        print("âœ… PoÅ‚Ä…czenie z Ollama udane")
    else:
        print("âŒ BÅ‚Ä…d poÅ‚Ä…czenia z Ollama")
        return False
    
    # Test analizy
    print("\n2. Test analizy treÅ›ci...")
    test_text = "Klient dzwoni w sprawie reklamacji produktu. Doradca jest uprzejmy i profesjonalny."
    
    result = analyzer.analyze_content(test_text, "call_center")
    
    if result["success"]:
        print("âœ… Analiza treÅ›ci udana")
        print(f"Model: {result['model_used']}")
        print(f"OdpowiedÅº: {result['raw_response'][:200]}...")
    else:
        print(f"âŒ BÅ‚Ä…d analizy: {result['error']}")
        return False
    
    # Test analizy wzorcÃ³w mÃ³wcÃ³w
    print("\n3. Test analizy wzorcÃ³w mÃ³wcÃ³w...")
    test_speakers = [
        {"speaker": "SPEAKER_00", "start": 0, "end": 10, "duration": 10},
        {"speaker": "SPEAKER_01", "start": 10, "end": 15, "duration": 5},
        {"speaker": "SPEAKER_00", "start": 15, "end": 25, "duration": 10}
    ]
    
    pattern_result = analyzer.analyze_speaker_patterns(test_speakers)
    if "error" not in pattern_result:
        print("âœ… Analiza wzorcÃ³w mÃ³wcÃ³w udana")
        print(f"Liczba mÃ³wcÃ³w: {pattern_result['speaker_count']}")
        print(f"DominujÄ…cy mÃ³wca: {pattern_result['dominant_speaker']}")
    else:
        print(f"âŒ BÅ‚Ä…d analizy wzorcÃ³w: {pattern_result['error']}")
    
    print("\nâœ… Test integracji z Ollama zakoÅ„czony pomyÅ›lnie!")
    return True

if __name__ == "__main__":
    test_ollama_integration() 